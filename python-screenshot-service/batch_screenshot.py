#!/usr/bin/env python3
"""
æ‰¹é‡æˆªå›¾å·¥å…· - ä¼˜åŒ–ç‰ˆ
æ¯æ¬¡è¿è¡Œåˆ›å»ºç‹¬ç«‹çš„æ—¶é—´ç›®å½•ï¼Œæ”¯æŒå¤šç§URLåˆ—è¡¨
"""
import asyncio
import sys
import os
import time
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# é¢„å®šä¹‰çš„URLé›†åˆ
URL_SETS = {
    "key_sites": {
        "name": "å…³é”®ç½‘ç«™ (5ä¸ª)",
        "description": "ä»12æ–‡ä»¶å¤¹æå–çš„æœ€é‡è¦ç½‘ç«™",
        "urls": [
            {"name": "Wave Life Sciences", "url": "https://wavelifesciences.com/pipeline/research-and-development/"},
            {"name": "Silence Therapeutics", "url": "https://silence-therapeutics.com/our-pipeline/default.aspx"},
            {"name": "Alnylam", "url": "https://www.alnylam.com/alnylam-rnai-pipeline"},
            {"name": "Arrowhead Pharma", "url": "https://arrowheadpharma.com/pipeline/"},
            {"name": "CRISPR Therapeutics", "url": "https://crisprtx.com/pipeline"}
        ]
    },
    "rnai_companies": {
        "name": "RNAiå…¬å¸ (10ä¸ª)",
        "description": "ä¸“æ³¨RNAiæŠ€æœ¯çš„ç”Ÿç‰©æŠ€æœ¯å…¬å¸",
        "urls": [
            {"name": "Alnylam", "url": "https://www.alnylam.com/alnylam-rnai-pipeline"},
            {"name": "Arrowhead Pharma", "url": "https://arrowheadpharma.com/pipeline/"},
            {"name": "Silence Therapeutics", "url": "https://silence-therapeutics.com/our-pipeline/default.aspx"},
            {"name": "Dicerna (Novo Nordisk)", "url": "https://www.novonordisk.com/science-and-technology/r-d-pipeline.html"},
            {"name": "SiRNA Omics", "url": "https://www.sirnaomics.com/cn/science-pipeline/pipeline/"},
            {"name": "Ionis", "url": "https://ionis.com/pipeline/independent?_format=json"},
            {"name": "Wave Life Sciences", "url": "https://wavelifesciences.com/pipeline/research-and-development/"},
            {"name": "Roche (RNAi)", "url": "https://www.roche.com/solutions/pipeline"},
            {"name": "Sarepta", "url": "https://www.sarepta.com/products-pipeline/pipelinel"},
            {"name": "ProQR", "url": "https://www.proqr.com/pipeline"}
        ]
    },
    "gene_editing": {
        "name": "åŸºå› ç¼–è¾‘å…¬å¸ (8ä¸ª)",
        "description": "CRISPRå’Œå…¶ä»–åŸºå› ç¼–è¾‘æŠ€æœ¯å…¬å¸",
        "urls": [
            {"name": "CRISPR Therapeutics", "url": "https://crisprtx.com/pipeline"},
            {"name": "Intellia Therapeutics", "url": "https://www.intelliatx.com/pipeline/"},
            {"name": "Beam Therapeutics", "url": "https://beamtx.com/pipeline/"},
            {"name": "Metagenomi", "url": "https://metagenomi.co/pipeline"},
            {"name": "Dyne Therapeutics", "url": "https://www.dyne-tx.com/pipeline/"},
            {"name": "PepGen", "url": "https://www.pepgen.com/pipeline/"},
            {"name": "Entrada Therapeutics", "url": "https://www.entradatx.com/pipeline"},
            {"name": "Avidity Biosciences", "url": "https://www.aviditybiosciences.com/pipeline/pipeline-overview"}
        ]
    },
    "big_pharma": {
        "name": "å¤§å‹åˆ¶è¯å…¬å¸ (6ä¸ª)",
        "description": "ä¼ ç»Ÿå¤§å‹åˆ¶è¯å…¬å¸çš„ç®¡çº¿",
        "urls": [
            {"name": "Novartis", "url": "https://www.novartis.com/research-development/novartis-pipeline"},
            {"name": "Roche", "url": "https://www.roche.com/solutions/pipeline"},
            {"name": "AstraZeneca", "url": "https://www.astrazeneca.com/our-therapy-areas/pipeline.html"},
            {"name": "Lilly", "url": "https://www.lilly.com/innovation/clinical-development-pipeline"},
            {"name": "Novo Nordisk", "url": "https://www.novonordisk.com/science-and-technology/r-d-pipeline.html"},
            {"name": "Regeneron", "url": "https://www.regeneron.com/science/investigational-pipeline"}
        ]
    },
    "all_sites": {
        "name": "æ‰€æœ‰ç½‘ç«™ (44ä¸ª)",
        "description": "12æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ç½‘ç«™",
        "urls": []  # å°†åœ¨è¿è¡Œæ—¶å¡«å……
    }
}

# å¡«å……æ‰€æœ‰ç½‘ç«™åˆ—è¡¨
def populate_all_sites():
    """å¡«å……æ‰€æœ‰ç½‘ç«™åˆ—è¡¨"""
    all_urls = []
    
    # æ·»åŠ æ‰€æœ‰å…¶ä»–é›†åˆçš„URLï¼Œå»é‡
    seen_urls = set()
    for set_key, url_set in URL_SETS.items():
        if set_key != "all_sites":
            for url_info in url_set["urls"]:
                if url_info["url"] not in seen_urls:
                    all_urls.append(url_info)
                    seen_urls.add(url_info["url"])
    
    # æ·»åŠ å…¶ä»–æœªåŒ…å«çš„URL
    additional_urls = [
        {"name": "Denali Therapeutics", "url": "https://www.denalitherapeutics.com/pipeline"},
        {"name": "Adarx", "url": "https://www.adarx.com/pipeline/"},
        {"name": "Ribolia", "url": "https://www.ribolia.com/pipeline"},
        {"name": "Atalanta Therapeutics", "url": "https://www.atalantatx.com/pipeline/"},
        {"name": "Rona Therapeutics", "url": "https://www.ronatherapeutics.com/pipeline"},
        {"name": "Olix Pharma", "url": "https://olixpharma.com/rnd/rnd03.php"},
        {"name": "Tangram Therapeutics", "url": "https://tangramtx.com/pipeline/"},
        {"name": "Switch Therapeutics", "url": "https://www.switchthera.com/our-science/"},
        {"name": "Arobic Therapeutics", "url": "https://www.arobiotx.com/pipeline"},
        {"name": "Sanegene Bio", "url": "https://www.sanegenebio.com/pipeline/"},
        {"name": "Sirius RNA", "url": "https://www.siriusrna.com/pipeline/index.html#pipeline"},
        {"name": "Synerk", "url": "https://synerk.cn/productinfo/883480.html"},
        {"name": "Aligos", "url": "https://aligos.com/science/scientific-overview/"},
        {"name": "Arbutus Bio", "url": "https://www.arbutusbio.com/pipeline/"},
        {"name": "Camp4 Therapeutics", "url": "https://www.camp4tx.com/pipeline/"},
        {"name": "Mina Therapeutics", "url": "https://minatx.com/pipeline/"},
        {"name": "Ractigen", "url": "https://www.ractigen.com/pipeline/"},
        {"name": "Judo Bio", "url": "https://judo.bio/pipeline/"},
        {"name": "Rigerna", "url": "https://www.rigerna.com/page/cpgx/"},
        {"name": "Siran Bio", "url": "https://www.siranbio.com/page/cpgx/"},
        {"name": "VisiRNA", "url": "https://www.visirna.com/pages/client/pplinea?version=v1"},
        {"name": "Hygeia Pharma", "url": "https://www.hygieiapharma.com/Pipeline/3.html"}
    ]
    
    for url_info in additional_urls:
        if url_info["url"] not in seen_urls:
            all_urls.append(url_info)
            seen_urls.add(url_info["url"])
    
    URL_SETS["all_sites"]["urls"] = all_urls

class BatchScreenshotManager:
    def __init__(self):
        self.session_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.base_dir = Path("screenshots")
        self.session_dir = self.base_dir / f"batch_{self.session_time}"
        self.session_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.images_dir = self.session_dir / "images"
        self.reports_dir = self.session_dir / "reports"
        self.images_dir.mkdir(exist_ok=True)
        self.reports_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“ æœ¬æ¬¡æˆªå›¾ä¼šè¯ç›®å½•: {self.session_dir}")
        print(f"ğŸ–¼ï¸ æˆªå›¾ä¿å­˜ç›®å½•: {self.images_dir}")
        print(f"ğŸ“Š æŠ¥å‘Šä¿å­˜ç›®å½•: {self.reports_dir}")
    
    async def run_batch_screenshot(self, url_set_key):
        """è¿è¡Œæ‰¹é‡æˆªå›¾"""
        if url_set_key not in URL_SETS:
            print(f"âŒ æœªçŸ¥çš„URLé›†åˆ: {url_set_key}")
            return
        
        url_set = URL_SETS[url_set_key]
        urls = url_set["urls"]
        
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æˆªå›¾: {url_set['name']}")
        print(f"ğŸ“‹ æè¿°: {url_set['description']}")
        print(f"ğŸ”¢ ç½‘ç«™æ•°é‡: {len(urls)}")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            from screenshot_service import ScreenshotService
            
            # åˆ›å»ºæˆªå›¾æœåŠ¡ï¼Œä½¿ç”¨æˆ‘ä»¬çš„å›¾ç‰‡ç›®å½•
            service = ScreenshotService(str(self.images_dir))
            
            # éªŒè¯æœåŠ¡
            print("\nğŸ§ª éªŒè¯æˆªå›¾æœåŠ¡...")
            test_result = await service.take_screenshot("https://httpbin.org/html")
            if not test_result.get("success"):
                print(f"âŒ æœåŠ¡éªŒè¯å¤±è´¥: {test_result.get('error')}")
                return
            print("âœ… æœåŠ¡éªŒè¯æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            return
        
        print(f"\n{'='*80}")
        print(f"ğŸ“¸ å¼€å§‹æˆªå›¾ä»»åŠ¡")
        print(f"{'='*80}")
        
        results = []
        start_time = time.time()
        
        for i, url_info in enumerate(urls, 1):
            result = await self.screenshot_single_url(service, url_info, i, len(urls))
            results.append(result)
            
            # è¿›åº¦æ˜¾ç¤º
            success_count = sum(1 for r in results if r.get("success"))
            print(f"   ğŸ“Š è¿›åº¦: {i}/{len(urls)} | æˆåŠŸ: {success_count} | å¤±è´¥: {i - success_count}")
            
            # URLé—´éš”
            if i < len(urls):
                await asyncio.sleep(1.5)
        
        total_time = time.time() - start_time
        
        # ç”ŸæˆæŠ¥å‘Š
        await self.generate_report(url_set_key, url_set, results, total_time)
        
        return results
    
    async def screenshot_single_url(self, service, url_info, index, total):
        """æˆªå›¾å•ä¸ªURL"""
        name = url_info["name"]
        url = url_info["url"]
        
        print(f"\n[{index:2d}/{total}] ğŸ“¸ {name}")
        print(f"           URL: {url}")
        
        start_time = time.time()
        
        try:
            result = await service.take_screenshot(url, {"headless": True})
            elapsed = time.time() - start_time
            
            if result.get("success"):
                filename = result.get("filename", "")
                print(f"           âœ… æˆåŠŸ ({elapsed:.1f}s) - {filename}")
                return {
                    "name": name,
                    "url": url,
                    "success": True,
                    "filename": filename,
                    "elapsed": elapsed,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                error = result.get("error", "æœªçŸ¥é”™è¯¯")
                print(f"           âŒ å¤±è´¥ ({elapsed:.1f}s) - {error}")
                return {
                    "name": name,
                    "url": url,
                    "success": False,
                    "error": error,
                    "elapsed": elapsed,
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            elapsed = time.time() - start_time
            print(f"           âŒ å¼‚å¸¸ ({elapsed:.1f}s) - {str(e)}")
            return {
                "name": name,
                "url": url,
                "success": False,
                "error": str(e),
                "elapsed": elapsed,
                "timestamp": datetime.now().isoformat()
            }
    
    async def generate_report(self, set_key, url_set, results, total_time):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        success_count = sum(1 for r in results if r.get("success"))
        failed_count = len(results) - success_count
        avg_time = sum(r.get("elapsed", 0) for r in results) / len(results) if results else 0
        
        # æ§åˆ¶å°æŠ¥å‘Š
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ‰¹é‡æˆªå›¾å®ŒæˆæŠ¥å‘Š")
        print(f"{'='*80}")
        print(f"ä»»åŠ¡é›†åˆ: {url_set['name']}")
        print(f"å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ€»è®¡ç½‘ç«™: {len(results)}")
        print(f"æˆåŠŸæˆªå›¾: {success_count} ä¸ª")
        print(f"å¤±è´¥æˆªå›¾: {failed_count} ä¸ª")
        print(f"æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
        print(f"æ€»è€—æ—¶: {total_time:.1f}s ({total_time/60:.1f}åˆ†é’Ÿ)")
        print(f"å¹³å‡è€—æ—¶: {avg_time:.1f}s")
        
        # æˆåŠŸåˆ—è¡¨
        successful_sites = [r for r in results if r.get("success")]
        if successful_sites:
            print(f"\nâœ… æˆåŠŸæˆªå›¾ ({len(successful_sites)}ä¸ª):")
            for i, r in enumerate(successful_sites, 1):
                print(f"  {i:2d}. {r['name']} ({r.get('elapsed', 0):.1f}s)")
        
        # å¤±è´¥åˆ—è¡¨
        failed_sites = [r for r in results if not r.get("success")]
        if failed_sites:
            print(f"\nâŒ å¤±è´¥æˆªå›¾ ({len(failed_sites)}ä¸ª):")
            for i, r in enumerate(failed_sites, 1):
                error = r.get('error', 'æœªçŸ¥é”™è¯¯')[:50]
                print(f"  {i:2d}. {r['name']} - {error}")
        
        # ä¿å­˜JSONæŠ¥å‘Š
        report_data = {
            "session_info": {
                "session_id": self.session_time,
                "url_set_key": set_key,
                "url_set_name": url_set['name'],
                "description": url_set['description'],
                "start_time": datetime.now().isoformat(),
                "session_dir": str(self.session_dir)
            },
            "summary": {
                "total": len(results),
                "success": success_count,
                "failed": failed_count,
                "success_rate": success_count/len(results)*100 if results else 0,
                "total_time": total_time,
                "average_time": avg_time
            },
            "results": results
        }
        
        json_report_file = self.reports_dir / f"report_{set_key}_{self.session_time}.json"
        with open(json_report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        html_report_file = self.reports_dir / f"report_{set_key}_{self.session_time}.html"
        await self.generate_html_report(html_report_file, report_data)
        
        print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   JSON: {json_report_file}")
        print(f"   HTML: {html_report_file}")
        print(f"   æˆªå›¾: {self.images_dir}")
    
    async def generate_html_report(self, html_file, report_data):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æ‰¹é‡æˆªå›¾æŠ¥å‘Š - {report_data['session_info']['url_set_name']}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; margin-bottom: 30px; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 30px; }}
        .stat-card {{ background: #f8f9fa; padding: 15px; border-radius: 6px; text-align: center; }}
        .stat-value {{ font-size: 24px; font-weight: bold; color: #007bff; }}
        .stat-label {{ color: #666; margin-top: 5px; }}
        .results-section {{ margin-top: 30px; }}
        .result-item {{ display: flex; align-items: center; padding: 10px; margin: 5px 0; border-radius: 4px; }}
        .success {{ background-color: #d4edda; border-left: 4px solid #28a745; }}
        .failure {{ background-color: #f8d7da; border-left: 4px solid #dc3545; }}
        .status-icon {{ margin-right: 10px; font-size: 18px; }}
        .site-name {{ font-weight: bold; margin-right: 10px; }}
        .site-url {{ color: #666; font-size: 12px; }}
        .elapsed-time {{ margin-left: auto; color: #666; }}
        .error-msg {{ color: #dc3545; font-size: 12px; margin-left: 10px; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“¸ æ‰¹é‡æˆªå›¾æŠ¥å‘Š</h1>
            <h2>{report_data['session_info']['url_set_name']}</h2>
            <p>{report_data['session_info']['description']}</p>
            <p>ä¼šè¯ID: {report_data['session_info']['session_id']}</p>
        </div>
        
        <div class="summary">
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['total']}</div>
                <div class="stat-label">æ€»è®¡ç½‘ç«™</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['success']}</div>
                <div class="stat-label">æˆåŠŸæˆªå›¾</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['failed']}</div>
                <div class="stat-label">å¤±è´¥æˆªå›¾</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['success_rate']:.1f}%</div>
                <div class="stat-label">æˆåŠŸç‡</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['total_time']:.1f}s</div>
                <div class="stat-label">æ€»è€—æ—¶</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{report_data['summary']['average_time']:.1f}s</div>
                <div class="stat-label">å¹³å‡è€—æ—¶</div>
            </div>
        </div>
        
        <div class="results-section">
            <h3>ğŸ“‹ è¯¦ç»†ç»“æœ</h3>
"""
        
        for i, result in enumerate(report_data['results'], 1):
            success = result.get('success', False)
            css_class = 'success' if success else 'failure'
            icon = 'âœ…' if success else 'âŒ'
            
            html_content += f"""
            <div class="result-item {css_class}">
                <span class="status-icon">{icon}</span>
                <div>
                    <div class="site-name">{i}. {result['name']}</div>
                    <div class="site-url">{result['url']}</div>
                    {f'<div class="error-msg">é”™è¯¯: {result.get("error", "")}</div>' if not success else ''}
                </div>
                <div class="elapsed-time">{result.get('elapsed', 0):.1f}s</div>
            </div>
"""
        
        html_content += """
        </div>
    </div>
</body>
</html>
"""
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

def show_menu():
    """æ˜¾ç¤ºèœå•"""
    print("\nğŸš€ æ‰¹é‡æˆªå›¾å·¥å…·")
    print("="*50)
    print("è¯·é€‰æ‹©è¦æˆªå›¾çš„ç½‘ç«™é›†åˆ:")
    print()
    
    for i, (key, url_set) in enumerate(URL_SETS.items(), 1):
        print(f"{i}. {url_set['name']}")
        print(f"   {url_set['description']}")
        print(f"   ç½‘ç«™æ•°é‡: {len(url_set['urls'])}")
        print()
    
    print("0. é€€å‡º")
    print("="*50)

async def main():
    # å¡«å……æ‰€æœ‰ç½‘ç«™åˆ—è¡¨
    populate_all_sites()
    
    while True:
        show_menu()
        
        try:
            choice = input("è¯·è¾“å…¥é€‰æ‹© (0-5): ").strip()
            
            if choice == "0":
                print("ğŸ‘‹ å†è§!")
                break
            
            # å°†é€‰æ‹©è½¬æ¢ä¸ºURLé›†åˆé”®
            url_set_keys = list(URL_SETS.keys())
            choice_index = int(choice) - 1
            
            if 0 <= choice_index < len(url_set_keys):
                selected_key = url_set_keys[choice_index]
                
                print(f"\nâœ… å·²é€‰æ‹©: {URL_SETS[selected_key]['name']}")
                confirm = input("ç¡®è®¤å¼€å§‹æˆªå›¾? (y/N): ").strip().lower()
                
                if confirm in ['y', 'yes']:
                    manager = BatchScreenshotManager()
                    await manager.run_batch_screenshot(selected_key)
                    
                    print(f"\nğŸ‰ æ‰¹é‡æˆªå›¾å®Œæˆ!")
                    input("æŒ‰å›è½¦é”®ç»§ç»­...")
                else:
                    print("âŒ å·²å–æ¶ˆ")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆæ•°å­—")
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    asyncio.run(main())