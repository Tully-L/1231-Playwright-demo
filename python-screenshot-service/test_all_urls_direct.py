#!/usr/bin/env python3
"""
æµ‹è¯•æ‰€æœ‰44ä¸ªURL - ç›´æ¥è°ƒç”¨æˆªå›¾æœåŠ¡
"""
import asyncio
import sys
import os
import time
import json
from datetime import datetime

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# ä»12æ–‡ä»¶å¤¹ä¸­æå–çš„æ‰€æœ‰44ä¸ªURL
ALL_URLS = [
    # Pythonæ–‡ä»¶ä¸­çš„URL
    {"name": "Wave Life Sciences", "url": "https://wavelifesciences.com/pipeline/research-and-development/"},
    {"name": "Silence Therapeutics", "url": "https://silence-therapeutics.com/our-pipeline/default.aspx"},
    
    # JavaScriptæ–‡ä»¶ä¸­çš„URL
    {"name": "Alnylam", "url": "https://www.alnylam.com/alnylam-rnai-pipeline"},
    {"name": "Arrowhead Pharma", "url": "https://arrowheadpharma.com/pipeline/"},
    {"name": "Ionis", "url": "https://ionis.com/pipeline/independent?_format=json"},
    {"name": "Avidity Biosciences", "url": "https://www.aviditybiosciences.com/pipeline/pipeline-overview"},
    {"name": "Lilly", "url": "https://www.lilly.com/innovation/clinical-development-pipeline"},
    {"name": "Novo Nordisk", "url": "https://www.novonordisk.com/science-and-technology/r-d-pipeline.html"},
    {"name": "Novartis", "url": "https://www.novartis.com/research-development/novartis-pipeline"},
    {"name": "Regeneron", "url": "https://www.regeneron.com/science/investigational-pipeline"},
    {"name": "Dyne Therapeutics", "url": "https://www.dyne-tx.com/pipeline/"},
    {"name": "Denali Therapeutics", "url": "https://www.denalitherapeutics.com/pipeline"},
    {"name": "Adarx", "url": "https://www.adarx.com/pipeline/"},
    {"name": "Ribolia", "url": "https://www.ribolia.com/pipeline"},
    {"name": "Intellia Therapeutics", "url": "https://www.intelliatx.com/pipeline/"},
    {"name": "Beam Therapeutics", "url": "https://beamtx.com/pipeline/"},
    {"name": "AstraZeneca", "url": "https://www.astrazeneca.com/our-therapy-areas/pipeline.html"},
    {"name": "Roche", "url": "https://www.roche.com/solutions/pipeline"},
    {"name": "Atalanta Therapeutics", "url": "https://www.atalantatx.com/pipeline/"},
    {"name": "Sarepta", "url": "https://www.sarepta.com/products-pipeline/pipelinel"},
    {"name": "Rona Therapeutics", "url": "https://www.ronatherapeutics.com/pipeline"},
    {"name": "CRISPR Therapeutics", "url": "https://crisprtx.com/pipeline"},
    {"name": "Olix Pharma", "url": "https://olixpharma.com/rnd/rnd03.php"},
    {"name": "Entrada Therapeutics", "url": "https://www.entradatx.com/pipeline"},
    {"name": "PepGen", "url": "https://www.pepgen.com/pipeline/"},
    {"name": "Tangram Therapeutics", "url": "https://tangramtx.com/pipeline/"},
    {"name": "Switch Therapeutics", "url": "https://www.switchthera.com/our-science/"},
    {"name": "Arobic Therapeutics", "url": "https://www.arobiotx.com/pipeline"},
    {"name": "SiRNA Omics", "url": "https://www.sirnaomics.com/cn/science-pipeline/pipeline/"},
    {"name": "Sanegene Bio", "url": "https://www.sanegenebio.com/pipeline/"},
    {"name": "Sirius RNA", "url": "https://www.siriusrna.com/pipeline/index.html#pipeline"},
    {"name": "Synerk", "url": "https://synerk.cn/productinfo/883480.html"},
    {"name": "Aligos", "url": "https://aligos.com/science/scientific-overview/"},
    {"name": "Arbutus Bio", "url": "https://www.arbutusbio.com/pipeline/"},
    {"name": "ProQR", "url": "https://www.proqr.com/pipeline"},
    {"name": "Metagenomi", "url": "https://metagenomi.co/pipeline"},
    {"name": "Camp4 Therapeutics", "url": "https://www.camp4tx.com/pipeline/"},
    {"name": "Mina Therapeutics", "url": "https://minatx.com/pipeline/"},
    {"name": "Ractigen", "url": "https://www.ractigen.com/pipeline/"},
    {"name": "Judo Bio", "url": "https://judo.bio/pipeline/"},
    {"name": "Rigerna", "url": "https://www.rigerna.com/page/cpgx/"},
    {"name": "Siran Bio", "url": "https://www.siranbio.com/page/cpgx/"},
    {"name": "VisiRNA", "url": "https://www.visirna.com/pages/client/pplinea?version=v1"},
    {"name": "Hygeia Pharma", "url": "https://www.hygieiapharma.com/Pipeline/3.html"}
]

async def test_single_url(service, url_info, index, total):
    """æµ‹è¯•å•ä¸ªURL"""
    name = url_info["name"]
    url = url_info["url"]
    
    print(f"[{index:2d}/{total}] ğŸ“¸ {name}")
    print(f"           URL: {url}")
    
    start_time = time.time()
    
    try:
        # ç›´æ¥è°ƒç”¨æˆªå›¾æœåŠ¡
        result = await service.take_screenshot(url, {"headless": True})
        elapsed = time.time() - start_time
        
        if result.get("success"):
            filename = result.get("filename", "")
            print(f"           âœ… æˆåŠŸ ({elapsed:.1f}s) - {filename}")
            return {
                "name": name,
                "url": url,
                "success": True,
                "filename": filename,
                "elapsed": elapsed
            }
        else:
            error = result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"           âŒ å¤±è´¥ ({elapsed:.1f}s) - {error}")
            return {
                "name": name,
                "url": url,
                "success": False,
                "error": error,
                "elapsed": elapsed
            }
            
    except Exception as e:
        elapsed = time.time() - start_time
        print(f"           âŒ å¼‚å¸¸ ({elapsed:.1f}s) - {str(e)}")
        return {
            "name": name,
            "url": url,
            "success": False,
            "error": str(e),
            "elapsed": elapsed
        }

async def test_all_urls():
    """æµ‹è¯•æ‰€æœ‰URL"""
    print("ğŸš€ æµ‹è¯•æ‰€æœ‰44ä¸ªURL - ç›´æ¥è°ƒç”¨æˆªå›¾æœåŠ¡")
    print("ğŸ¯ éªŒè¯Pythonåæ£€æµ‹æ–¹æ¡ˆçš„å®Œæ•´æ•ˆæœ\n")
    
    try:
        from screenshot_service import ScreenshotService
        
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = ScreenshotService("./screenshots")
        print("âœ… æˆªå›¾æœåŠ¡å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # å…ˆæµ‹è¯•ç®€å•URLéªŒè¯æœåŠ¡æ­£å¸¸
        print("\nğŸ§ª éªŒè¯æœåŠ¡æ­£å¸¸...")
        simple_result = await service.take_screenshot("https://httpbin.org/html")
        
        if not simple_result.get("success"):
            print(f"âŒ æœåŠ¡éªŒè¯å¤±è´¥: {simple_result.get('error')}")
            return
        
        print("âœ… æœåŠ¡éªŒè¯æˆåŠŸï¼Œå¼€å§‹æ‰¹é‡æµ‹è¯•\n")
        
    except Exception as e:
        print(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    print("="*80)
    print("ğŸ“¸ å¼€å§‹æ‰¹é‡æˆªå›¾æµ‹è¯•")
    print("="*80)
    
    results = []
    batch_size = 5  # æ¯æ‰¹å¤„ç†5ä¸ª
    
    for i in range(0, len(ALL_URLS), batch_size):
        batch = ALL_URLS[i:i + batch_size]
        batch_num = i // batch_size + 1
        total_batches = (len(ALL_URLS) + batch_size - 1) // batch_size
        
        print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_num}/{total_batches}: å¤„ç† {len(batch)} ä¸ªURL")
        print("-" * 60)
        
        batch_start = time.time()
        
        for j, url_info in enumerate(batch):
            result = await test_single_url(service, url_info, i + j + 1, len(ALL_URLS))
            results.append(result)
            
            # æ¯ä¸ªURLä¹‹é—´ç­‰å¾…1ç§’
            if j < len(batch) - 1:
                await asyncio.sleep(1)
        
        batch_elapsed = time.time() - batch_start
        success_in_batch = sum(1 for r in batch if results[i + batch.index(r)].get("success"))
        
        print(f"\nğŸ“Š æ‰¹æ¬¡ {batch_num} å®Œæˆ: {success_in_batch}/{len(batch)} æˆåŠŸ ({batch_elapsed:.1f}s)")
        
        # æ‰¹æ¬¡é—´ç­‰å¾…3ç§’
        if i + batch_size < len(ALL_URLS):
            print("â³ æ‰¹æ¬¡é—´ç­‰å¾… 3 ç§’...\n")
            await asyncio.sleep(3)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    generate_final_report(results)

def generate_final_report(results):
    """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
    total = len(results)
    success_count = sum(1 for r in results if r.get("success"))
    failed_count = total - success_count
    
    total_time = sum(r.get("elapsed", 0) for r in results)
    avg_time = total_time / total if total > 0 else 0
    
    print("\n" + "="*80)
    print("ğŸ“Š å®Œæ•´æµ‹è¯•æŠ¥å‘Š - Pythonåæ£€æµ‹æˆªå›¾æœåŠ¡")
    print("="*80)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ€»è®¡ç½‘ç«™: {total}")
    print(f"æˆåŠŸæˆªå›¾: {success_count} ä¸ª")
    print(f"å¤±è´¥æˆªå›¾: {failed_count} ä¸ª")
    print(f"æˆåŠŸç‡: {success_count/total*100:.1f}%")
    print(f"æ€»è€—æ—¶: {total_time:.1f}s ({total_time/60:.1f}åˆ†é’Ÿ)")
    print(f"å¹³å‡è€—æ—¶: {avg_time:.1f}s")
    
    # æˆåŠŸçš„ç½‘ç«™
    successful_sites = [r for r in results if r.get("success")]
    if successful_sites:
        print(f"\nâœ… æˆåŠŸæˆªå›¾çš„ç½‘ç«™ ({len(successful_sites)}ä¸ª):")
        for i, r in enumerate(successful_sites, 1):
            print(f"  {i:2d}. {r['name']} ({r.get('elapsed', 0):.1f}s)")
    
    # å¤±è´¥çš„ç½‘ç«™
    failed_sites = [r for r in results if not r.get("success")]
    if failed_sites:
        print(f"\nâŒ å¤±è´¥çš„ç½‘ç«™ ({len(failed_sites)}ä¸ª):")
        for i, r in enumerate(failed_sites, 1):
            error = r.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"  {i:2d}. {r['name']} - {error}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = f"complete_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "test_type": "complete_direct_screenshot_test",
            "summary": {
                "total": total,
                "success": success_count,
                "failed": failed_count,
                "success_rate": success_count/total*100 if total > 0 else 0,
                "total_time": total_time,
                "average_time": avg_time
            },
            "results": results
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ€§èƒ½åˆ†æ
    print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
    if success_count/total >= 0.9:
        print(f"   ğŸ‰ ä¼˜ç§€! æˆåŠŸç‡ {success_count/total*100:.1f}% - Pythonåæ£€æµ‹æ–¹æ¡ˆéå¸¸æœ‰æ•ˆ")
    elif success_count/total >= 0.7:
        print(f"   âœ… è‰¯å¥½! æˆåŠŸç‡ {success_count/total*100:.1f}% - æ–¹æ¡ˆåŸºæœ¬æœ‰æ•ˆ")
    elif success_count/total >= 0.5:
        print(f"   âš ï¸ ä¸€èˆ¬! æˆåŠŸç‡ {success_count/total*100:.1f}% - éœ€è¦ä¼˜åŒ–")
    else:
        print(f"   âŒ è¾ƒå·®! æˆåŠŸç‡ {success_count/total*100:.1f}% - éœ€è¦é‡æ–°è¯„ä¼°æ–¹æ¡ˆ")
    
    if avg_time <= 10:
        print(f"   âš¡ é€Ÿåº¦ä¼˜ç§€! å¹³å‡ {avg_time:.1f}s/ç½‘ç«™")
    elif avg_time <= 20:
        print(f"   ğŸš€ é€Ÿåº¦è‰¯å¥½! å¹³å‡ {avg_time:.1f}s/ç½‘ç«™")
    else:
        print(f"   ğŸŒ é€Ÿåº¦è¾ƒæ…¢! å¹³å‡ {avg_time:.1f}s/ç½‘ç«™")
    
    print(f"\nğŸ¯ ç»“è®º:")
    if success_count > 0:
        print(f"   â€¢ Python + Playwright-Stealth æ–¹æ¡ˆå¯è¡Œ")
        print(f"   â€¢ æˆåŠŸç»•è¿‡äº† {success_count} ä¸ªç½‘ç«™çš„åçˆ¬ä¿æŠ¤")
        print(f"   â€¢ å¯ä»¥ä½œä¸ºJavaScriptæ–¹æ¡ˆçš„æœ‰æ•ˆè¡¥å……")
        
        if success_count == total:
            print(f"   â€¢ ğŸ† å®Œç¾è¡¨ç°! å¯ä»¥æ›¿ä»£åŸæœ‰æ–¹æ¡ˆ")

async def main():
    try:
        await test_all_urls()
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())